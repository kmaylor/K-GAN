{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from itertools import product\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape, Input, Lambda\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Cropping2D\n",
    "from keras.layers import LeakyReLU, Dropout, UpSampling2D, AveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model\n",
    "from keras.backend import int_shape, tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PG_GAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "    \n",
    "    def discriminator(self):\n",
    "        \n",
    "        if self.D:\n",
    "            return self.D\n",
    "        \n",
    "        depth = 64\n",
    "        input_shape = (28, 28, 1)\n",
    "        \n",
    "        x = Input(shape=input_shape)\n",
    "        y = AveragePooling2D(pool_size = 2)(x)\n",
    "       # y = Conv2D(depth, 4, strides=1, padding = 'same')(y)\n",
    "       # y = LeakyReLU(alpha=0.2)(y)\n",
    "       # y = Dropout(.2)(y)\n",
    "        y = AveragePooling2D(pool_size = 2)(y)\n",
    "        #y = Conv2D(depth*2, 4, strides=1, padding = 'same')(y)\n",
    "        #y = LeakyReLU(alpha=0.2)(y)\n",
    "        #y = Dropout(.2)(y)\n",
    "        y = AveragePooling2D(pool_size = 2)(y)\n",
    "        y = Conv2D(depth*4, 4, strides=1, padding = 'same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = Dropout(.2)(y)\n",
    "        \n",
    "        y = Flatten()(y)\n",
    "        y = Dense(1,activation = 'sigmoid')(y)\n",
    "        self.D = Model(x,y)\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "    \n",
    "    def generator(self):\n",
    "        \n",
    "        if self.G:\n",
    "            return self.G\n",
    "        depth = 64\n",
    "        dim = 4#self.D.layers[-2].input_shape[1]\n",
    "        x = Input(shape=(100,))\n",
    "        y = Dense(depth*4*dim*dim,)(x)\n",
    "        y = Reshape((dim, dim, depth*4))(y)\n",
    "        y = UpSampling2D(2,interpolation='bilinear')(y)\n",
    "        y = Conv2D(depth*2, 4, strides=1, padding = 'same')(y)\n",
    "        y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = UpSampling2D(2,interpolation='bilinear')(y)\n",
    "        #y = Conv2D(depth, 4, strides=1, padding = 'same')(y)\n",
    "        #y = LeakyReLU(alpha=0.2)(y)\n",
    "        y = UpSampling2D(2,interpolation='bilinear')(y)\n",
    "        #y = Conv2D(1, 4, strides=1, padding = 'same')(y)\n",
    "        #y = LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "        y = Activation('tanh')(y)\n",
    "        crop = int((int_shape(y)[1]-self.D.input_shape[1])/2)\n",
    "        y = Cropping2D(cropping=((crop,crop),(crop,crop)))(y)\n",
    "        self.G = Model(x,y)\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = Adam(lr=0.0002,beta_1=0.5, decay=0)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "                    metrics=['binary_accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = Adam(lr=0.0002,beta_1=0.5, decay=0)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        discriminator = self.discriminator()\n",
    "        discriminator.trainable=False\n",
    "        self.AM.add(discriminator)\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "                metrics=['binary_accuracy'])\n",
    "        discriminator.trainable=True\n",
    "        self.AM.summary()\n",
    "        return self.AM\n",
    "    \n",
    "#     def replace_layer(self, model, layer_id, new_layer):\n",
    "\n",
    "#         layers = [l for l in model.layers]\n",
    "\n",
    "#         x = layers[0].output\n",
    "#         for i in range(1, len(layers)):\n",
    "#             if i == layer_id:\n",
    "#                 x = new_layer(x)\n",
    "#             else:\n",
    "#                 x = layers[i](x)\n",
    "\n",
    "#         new_model = Model(inputs=layers[0].input, outputs=x)\n",
    "#         return new_model\n",
    "    \n",
    "    def insert_layer(self, model, layer_id, new_layer):\n",
    "\n",
    "        layers = [l for l in model.layers]\n",
    "\n",
    "        x = layers[0].output\n",
    "        for i in range(1, len(layers)):\n",
    "            if i == layer_id:\n",
    "                x = new_layer(x)\n",
    "            x = layers[i](x)\n",
    "\n",
    "        new_model = Model(inputs=layers[0].input, outputs=x)\n",
    "        return new_model\n",
    "    \n",
    "    def increase_res(self):\n",
    "        generator = self.generator()\n",
    "        discriminator = self.discriminator()\n",
    "        discriminator.layers.pop(0)\n",
    "        newDInput = Input(shape=(7,7,16))\n",
    "        newD = Conv2D(49, 4, strides=2, padding = 'same')(newDInput)\n",
    "        newD = LeakyReLU(alpha=0.2)(newD)\n",
    "        newDOutput = discriminator(newD)\n",
    "        discriminator = Model(inputs=newDInput,outputs=newDOutput)\n",
    "        self.D = discriminator\n",
    "        self.D.summary()\n",
    "        \n",
    "        generator =  self.insert_layer(generator,len(generator.layers)-2,Conv2D(16, 4, strides=1, padding='same'))\n",
    "        generator =  self.insert_layer(generator,len(generator.layers)-2,LeakyReLU(alpha=0.2))\n",
    "        generator =  self.insert_layer(generator,len(generator.layers)-2,BatchNormalization(momentum=0.9))\n",
    "        #crop = int((int_shape(generator.layers[-2].output)[1]-discriminator.input_shape[1])/2)\n",
    "        #print(discriminator.input_shape,crop)\n",
    "        generator =  self.replace_layer(generator,len(generator.layers)-1,Cropping2D(cropping=((1,0),(1,0))))\n",
    "        self.G = generator\n",
    "        self.G.summary()\n",
    "        \n",
    "        optimizer = Adam(lr=0.001,beta_1=0,beta_2=0.99, decay=0)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.D)\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "        optimizer = Adam(lr=0.001,beta_1=0,beta_2=0.99, decay=0)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.G)\n",
    "        discriminator.trainable=False\n",
    "        self.AM.add(discriminator)\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        self.AM.summary()\n",
    "        discriminator.trainable=True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        (self.x_train, _), (_, _) = mnist.load_data()\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)/255*2-1\n",
    "\n",
    "        self.PGGAN = PG_GAN()\n",
    "        self.discriminator =  self.PGGAN.discriminator_model()\n",
    "        self.adversarial = self.PGGAN.adversarial_model()\n",
    "        self.generator = self.PGGAN.generator()\n",
    "        self.res_scale=7\n",
    "    def increase_res(self):\n",
    "        self.PGGAN.increase_res()\n",
    "        self.discriminator =  self.PGGAN.discriminator_model()\n",
    "        self.adversarial = self.PGGAN.adversarial_model()\n",
    "        self.generator = self.PGGAN.generator()\n",
    "        self.res_scale=4\n",
    "    \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.normal(loc=0., scale=1., size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.normal(loc=0., scale=1., size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            if i%50==0:\n",
    "                print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :,0]\n",
    "            #image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "    def add_output_layer(self, model, new_layer):\n",
    "        x = new_layer(model.layers[-1].output)\n",
    "        return Model(inputs = model.inputs, outputs = x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 3, 3, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3, 3, 256)         4352      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 2305      \n",
      "=================================================================\n",
      "Total params: 6,657\n",
      "Trainable params: 6,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 8, 8, 128)         524416    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)    (None, 28, 28, 128)       0         \n",
      "=================================================================\n",
      "Total params: 938,112\n",
      "Trainable params: 938,112\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 128 != 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3630e70f676e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmnist_dcgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNIST_DCGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmnist_dcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmnist_dcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmnist_dcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave2file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-3769bfb846fe>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPGGAN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPG_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPGGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madversarial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPGGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madversarial_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPGGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-7ebbdcf344a4>\u001b[0m in \u001b[0;36madversarial_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n\u001b[0;32m     86\u001b[0m                 metrics=['binary_accuracy'])\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[1;34m(self, inputs, masks)\u001b[0m\n\u001b[0;32m    719\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                             output_tensors = to_list(\n\u001b[1;32m--> 721\u001b[1;33m                                 layer.call(computed_tensor, **kwargs))\n\u001b[0m\u001b[0;32m    722\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[0;32m    723\u001b[0m                                                               computed_mask)\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3648\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3649\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3650\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         data_format=data_format)\n\u001b[0m\u001b[0;32m    780\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, filter_shape, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    837\u001b[0m           \u001b[1;34m\"number of input channels does not match corresponding dimension of \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m           \"filter, {} != {}\".format(input_channels_dim,\n\u001b[1;32m--> 839\u001b[1;33m                                     filter_shape[num_spatial_dims]))\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[1;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 128 != 1"
     ]
    }
   ],
   "source": [
    "mnist_dcgan = MNIST_DCGAN()\n",
    "mnist_dcgan.train(train_steps=2000, batch_size=256, save_interval=500)\n",
    "mnist_dcgan.plot_images(fake=True)\n",
    "mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
