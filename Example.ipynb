{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing necessary packages and modules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Keras version = 2.2.4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_1 (Conv2D)            (None, 14, 14, 64)        1088      \n",
      "_________________________________________________________________\n",
      "LRelu_D1 (LeakyReLU)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "DO_D1 (Dropout)              (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_D2 (Conv2D)           (None, 7, 7, 128)         131200    \n",
      "_________________________________________________________________\n",
      "LRelu_D2 (LeakyReLU)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_D3 (Conv2D)           (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "LRelu_D3 (LeakyReLU)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "DO_D3 (Dropout)              (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_D4 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "LRelu_D4 (LeakyReLU)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_D5 (Conv2D)           (None, 4, 4, 1024)        2098176   \n",
      "_________________________________________________________________\n",
      "LRelu_D5 (LeakyReLU)         (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "DO_D5 (Dropout)              (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "Dense_D (Dense)              (None, 1)                 16385     \n",
      "_________________________________________________________________\n",
      "Sigmoid (Activation)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,869,057\n",
      "Trainable params: 4,869,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_G (Dense)              (None, 8192)              532480    \n",
      "_________________________________________________________________\n",
      "LRelu_G1 (LeakyReLU)         (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "Reshape (Reshape)            (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "BN_G1 (BatchNormalization)   (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "UpSample_1 (UpSampling2D)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G1 (Conv2D)           (None, 8, 8, 256)         2097408   \n",
      "_________________________________________________________________\n",
      "LRelu_G2 (LeakyReLU)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "BN_G2 (BatchNormalization)   (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "UpSample_2 (UpSampling2D)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G2 (Conv2D)           (None, 16, 16, 128)       524416    \n",
      "_________________________________________________________________\n",
      "LRelu_G3 (LeakyReLU)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "BN_G3 (BatchNormalization)   (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "UpSample_3 (UpSampling2D)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G3 (Conv2D)           (None, 32, 32, 64)        131136    \n",
      "_________________________________________________________________\n",
      "LRelu_G4 (LeakyReLU)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "BN_G4 (BatchNormalization)   (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "UpSample_4 (UpSampling2D)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G4 (Conv2D)           (None, 32, 32, 32)        32800     \n",
      "_________________________________________________________________\n",
      "LRelu_G5 (LeakyReLU)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "BN_G5 (BatchNormalization)   (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "UpSample_5 (UpSampling2D)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_G5 (Conv2D)           (None, 32, 32, 1)         129       \n",
      "_________________________________________________________________\n",
      "Tanh (Activation)            (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "Crop2D (Cropping2D)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 3,322,337\n",
      "Trainable params: 3,320,353\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Discriminator (Sequential)   (None, 1)                 4869057   \n",
      "=================================================================\n",
      "Total params: 4,869,057\n",
      "Trainable params: 4,869,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Generator (Sequential)       (None, 28, 28, 1)         3322337   \n",
      "_________________________________________________________________\n",
      "Discriminator (Sequential)   (None, 1)                 4869057   \n",
      "=================================================================\n",
      "Total params: 8,191,394\n",
      "Trainable params: 3,320,353\n",
      "Non-trainable params: 4,871,041\n",
      "_________________________________________________________________\n",
      "Training Beginning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\KGAN\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [D loss: 0.693991, acc: 0.500000]  [A loss: 0.680135, acc: 1.000000]\n",
      "100: [D loss: 0.705526, acc: 0.578125]  [A loss: 0.917409, acc: 0.140625]\n",
      "200: [D loss: 0.651513, acc: 0.656250]  [A loss: 0.775011, acc: 0.109375]\n",
      "300: [D loss: 0.724002, acc: 0.312500]  [A loss: 0.733994, acc: 0.218750]\n",
      "400: [D loss: 0.689276, acc: 0.640625]  [A loss: 0.785617, acc: 0.171875]\n",
      "500: [D loss: 0.681053, acc: 0.562500]  [A loss: 0.791416, acc: 0.000000]\n",
      "600: [D loss: 0.641442, acc: 0.718750]  [A loss: 0.798959, acc: 0.093750]\n",
      "700: [D loss: 0.537315, acc: 0.796875]  [A loss: 0.739764, acc: 0.390625]\n",
      "800: [D loss: 0.622728, acc: 0.703125]  [A loss: 0.851751, acc: 0.093750]\n",
      "900: [D loss: 0.714064, acc: 0.390625]  [A loss: 0.742012, acc: 0.250000]\n",
      "1000: [D loss: 0.686316, acc: 0.640625]  [A loss: 0.770813, acc: 0.281250]\n",
      "1100: [D loss: 0.657485, acc: 0.625000]  [A loss: 0.864635, acc: 0.125000]\n",
      "1200: [D loss: 0.724025, acc: 0.421875]  [A loss: 0.793718, acc: 0.093750]\n",
      "1300: [D loss: 0.700319, acc: 0.421875]  [A loss: 0.789121, acc: 0.109375]\n",
      "1400: [D loss: 0.689866, acc: 0.593750]  [A loss: 0.771931, acc: 0.218750]\n",
      "1500: [D loss: 0.636949, acc: 0.703125]  [A loss: 0.763471, acc: 0.265625]\n",
      "1600: [D loss: 0.682510, acc: 0.531250]  [A loss: 0.735141, acc: 0.406250]\n",
      "1700: [D loss: 0.681218, acc: 0.531250]  [A loss: 0.733663, acc: 0.343750]\n",
      "1800: [D loss: 0.648511, acc: 0.625000]  [A loss: 0.756490, acc: 0.312500]\n",
      "1900: [D loss: 0.718830, acc: 0.484375]  [A loss: 0.753706, acc: 0.218750]\n",
      "2000: [D loss: 0.671737, acc: 0.562500]  [A loss: 0.747859, acc: 0.281250]\n",
      "2100: [D loss: 0.679062, acc: 0.515625]  [A loss: 0.759604, acc: 0.265625]\n",
      "2200: [D loss: 0.656365, acc: 0.625000]  [A loss: 0.764896, acc: 0.187500]\n",
      "2300: [D loss: 0.683882, acc: 0.546875]  [A loss: 0.765959, acc: 0.125000]\n",
      "2400: [D loss: 0.677112, acc: 0.578125]  [A loss: 0.732581, acc: 0.343750]\n",
      "2500: [D loss: 0.690088, acc: 0.562500]  [A loss: 0.757837, acc: 0.265625]\n",
      "2600: [D loss: 0.664941, acc: 0.578125]  [A loss: 0.800409, acc: 0.250000]\n",
      "2700: [D loss: 0.689156, acc: 0.515625]  [A loss: 0.725892, acc: 0.375000]\n",
      "2800: [D loss: 0.671128, acc: 0.640625]  [A loss: 0.785142, acc: 0.281250]\n",
      "2900: [D loss: 0.658050, acc: 0.546875]  [A loss: 0.766438, acc: 0.375000]\n",
      "3000: [D loss: 0.683575, acc: 0.484375]  [A loss: 0.753885, acc: 0.281250]\n",
      "3100: [D loss: 0.700251, acc: 0.515625]  [A loss: 0.702678, acc: 0.453125]\n",
      "3200: [D loss: 0.686843, acc: 0.531250]  [A loss: 0.841720, acc: 0.187500]\n",
      "3300: [D loss: 0.692291, acc: 0.484375]  [A loss: 0.735325, acc: 0.312500]\n",
      "3400: [D loss: 0.676546, acc: 0.593750]  [A loss: 0.741253, acc: 0.250000]\n",
      "3500: [D loss: 0.679846, acc: 0.546875]  [A loss: 0.724478, acc: 0.343750]\n",
      "3600: [D loss: 0.699565, acc: 0.453125]  [A loss: 0.737429, acc: 0.328125]\n",
      "3700: [D loss: 0.700831, acc: 0.515625]  [A loss: 0.753179, acc: 0.375000]\n",
      "3800: [D loss: 0.649125, acc: 0.671875]  [A loss: 0.792527, acc: 0.250000]\n",
      "3900: [D loss: 0.662225, acc: 0.625000]  [A loss: 0.754913, acc: 0.265625]\n",
      "4000: [D loss: 0.666477, acc: 0.578125]  [A loss: 0.765345, acc: 0.312500]\n",
      "4100: [D loss: 0.653974, acc: 0.703125]  [A loss: 0.756182, acc: 0.296875]\n",
      "4200: [D loss: 0.690593, acc: 0.531250]  [A loss: 0.752466, acc: 0.296875]\n",
      "4300: [D loss: 0.677851, acc: 0.546875]  [A loss: 0.776451, acc: 0.390625]\n",
      "4400: [D loss: 0.710984, acc: 0.453125]  [A loss: 0.802614, acc: 0.234375]\n",
      "4500: [D loss: 0.707933, acc: 0.562500]  [A loss: 0.778672, acc: 0.328125]\n",
      "4600: [D loss: 0.670367, acc: 0.609375]  [A loss: 0.800792, acc: 0.218750]\n",
      "4700: [D loss: 0.638822, acc: 0.625000]  [A loss: 0.789961, acc: 0.218750]\n",
      "4800: [D loss: 0.707476, acc: 0.515625]  [A loss: 0.775394, acc: 0.343750]\n",
      "4900: [D loss: 0.654620, acc: 0.578125]  [A loss: 0.809235, acc: 0.234375]\n",
      "5000: [D loss: 0.691321, acc: 0.390625]  [A loss: 0.800811, acc: 0.281250]\n",
      "5100: [D loss: 0.690780, acc: 0.546875]  [A loss: 0.778729, acc: 0.343750]\n",
      "5200: [D loss: 0.699848, acc: 0.515625]  [A loss: 0.830154, acc: 0.250000]\n",
      "5300: [D loss: 0.665111, acc: 0.625000]  [A loss: 0.800161, acc: 0.265625]\n",
      "5400: [D loss: 0.597763, acc: 0.640625]  [A loss: 0.788068, acc: 0.359375]\n",
      "5500: [D loss: 0.652706, acc: 0.593750]  [A loss: 0.839379, acc: 0.296875]\n",
      "5600: [D loss: 0.641342, acc: 0.578125]  [A loss: 0.790001, acc: 0.312500]\n",
      "5700: [D loss: 0.744925, acc: 0.484375]  [A loss: 0.771019, acc: 0.359375]\n",
      "5800: [D loss: 0.670991, acc: 0.531250]  [A loss: 0.827666, acc: 0.375000]\n",
      "5900: [D loss: 0.719913, acc: 0.437500]  [A loss: 0.854788, acc: 0.281250]\n",
      "6000: [D loss: 0.606969, acc: 0.671875]  [A loss: 0.909653, acc: 0.171875]\n",
      "6100: [D loss: 0.619949, acc: 0.640625]  [A loss: 0.851334, acc: 0.281250]\n",
      "6200: [D loss: 0.679318, acc: 0.609375]  [A loss: 0.784648, acc: 0.359375]\n"
     ]
    }
   ],
   "source": [
    "from example import MNISTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
